---
title: "ConvNet 소개 - (1) Introduction"
category: Computer vision
tag: ["Convolutional neural networks", "ConvNet"]
---

Computer vision 관련 업무를 하면서 가장 먼저 들은게 **convolutional nerual networks** (줄여서 **ConvNet**) 라는 구조의 deep learning 네트워크이고, 관련 자료를 살펴보면 computer vision 분야의 다양한 네트워크 기본 구조가 ConvNet 구조를 바탕으로 한다는 사실을 알 수 있었어.

그래서 오늘부터 몇 회에 걸쳐 "ConvNet 소개" 라는 제목으로 ConvNet 에 대한 전반적인 내용을 정리하려고 해.

해당 포스팅들은 다음의 관련 자료를 참고해서 작성했어.

 - [Deep Learning - chapter 12, Subir Varma and Sanjiv Das](https://srdas.github.io/DLBook/ConvNets.html)

--- 
## Fully connected deep nerual network 는 이미지 처리에 적절하지 않다..

ConvNet 은 1960년대 Hubel and Wiesel 이 고양이를 인식하는 시스템을 만든 것에서 처음 고안되었고, Fukushima 에 의해 NeoCognitron, 1998년 LeCun 에 의해 LeNet5 로 발전했어. 

2012년이 될 때까지 많은 연구들이 이루어지지 않았지만, ILSVRC 에서 우승을 하면서 다시 많은 관심을 받게 되었고 이후 ConvNet 이 computer vision 분야에 가장 powerful 한 기본 네트워크가 되었지.

그럼 왜 이미지를 분석할 때 fully connected network 대신 ConvNet 을 사용할까?
ConvNet 이 기존의 fully connected network 와 다른 점은 무엇일까?

이미지 분석에서 fully connected network 적용은 다음의 두 가지 문제를 가지고 있어.

 - 엄청난 수의 parameter 가 필요하다. 따라서 층을 많이 쌓기 어렵다.
   + 예를들어, $200\times 200$ 이미지가 있으면, 하나의 노드 연결에 40,000개의 가중치가 필요
   + 첫 번째 hidden layer 에 100개 노드가 있으면, 4백만개 가중치 필요..
   + 이 많은 para 에 overfitting 방지하려면, 엄청난 데이터 필요

 - 이미지 translation 에 민감하다. 즉, 이미지가 조금만 변형되면 아예 다른 결과 산출한다.
   + Fully connected net 은 이미지와 같은 사이즈의 template 사용.
   + 하나하나의 노드는 해당 template matching 결과.
   + 그러므로 translation 을 잡으려면, 상당히 많은 template/node 가 필요.

위와 같은 문제점으로 fully connected network 를 이미지 분석에 사용하는 것은 적절치 않아.

## ConvNet motivation

CIFAR-10 이미지는 $32\times 32 \times 3$ 이미지로 구성되어있고, 10개 클래스 중 하나의 레이블이 달려있어.

해당 이미지를 분류하는 모형을 fully connected network 로 구성해보자.

https://i.imgur.com/i0xfcGA.png

10개 노드를 갖는 layer 와 inpuy layer 를 연결하면, pre-activation $z_k$ 는 다음과 같이 구할 수 있어.

 - $z_k = \sum_{i=1}^3072 w_{ki} x_i + b_k$

$k$ 노드는 input layer 의 각 노드값 $x_i$ 와 그에 대응되는 가중치 $w_{ki}$ 의 곱으로 구성되어있고, 이는 아래 그림과 같이 input 사이즈와 동일한 template 을 matching 한 것으로 생각할 수 있어.

https://i.imgur.com/Lm3A2m4.png

그럼 우리는 다음의 질문을 할 수 있어.

_전체 이미지에 template 를 적용하는 것이 아닌, 더 작은 template 로 local 하게 matching 하는 건 어떨까?_

작은 사이즈의 template 를 적용하는 경우, fully connected network 의 문제를 해결할 수 있어.

 - Smaller templates need a smaller filter size and thus fewer parameters.
 - Even if the object being detected moves around the image, the same template or filter can still be used, thus leading to translational invariance.

더 디테일하게 이야기하면

Template(filter) 사이즈를 줄여서 template matching 하는 경우, local 한 영역 단위로 패턴을 찾기 때문에 translational invariant 하게 돼.
또한 template 을 더 적은 수의 parameter 로 구성해서, 학습할 para 수가 상당히 줄어들게 돼.

즉, 네트워크 architecture 에 일종의 제약조건을 주어서 이미지 패턴 인식 및 학습 효율성을 향상시키는 깔끔한 구조를 만든거야.

https://i.imgur.com/f9LFYZ2.png
